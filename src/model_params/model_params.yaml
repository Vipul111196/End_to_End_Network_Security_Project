Decision Tree:
  criterion: ['gini', 'entropy', 'log_loss']
  # splitter: ['best', 'random']
  # max_features: ['sqrt', 'log2']

Random Forest:
  # criterion: ['gini', 'entropy']
  # max_features: ['sqrt', 'log2']
  n_estimators: [8, 32, 128]

Gradient Boosting:
  learning_rate: [0.1, 0.01, 0.05]
  subsample: [0.6, 0.75, 0.9]
  # criterion: ['squared_error', 'friedman_mse']
  # max_features: ['auto', 'sqrt']
  n_estimators: [8, 64, 128]

Logistic Regression: {}

AdaBoost:
  learning_rate: [0.1, 0.01, 0.001]
  n_estimators: [8, 32, 128]
